{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0492035",
   "metadata": {},
   "source": [
    "Considering Python 2.7.\n",
    "1. Providing necessary dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6923b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Common arekit dependencies.\n",
    "from arekit.common.entities.formatters.types import EntityFormattersService\n",
    "from arekit.common.evaluation.evaluators.modes import EvaluationModes\n",
    "from arekit.common.evaluation.evaluators.two_class import TwoClassEvaluator\n",
    "from arekit.common.experiment.data_type import DataType\n",
    "from arekit.common.experiment.folding.types import FoldingType\n",
    "from arekit.common.experiment.scales.factory import create_labels_scaler\n",
    "from arekit.common.utils import progress_bar_defined\n",
    "\n",
    "# Contributaional part from arekit library.\n",
    "from arekit.contrib.bert.output.eval_helper import EvalHelper\n",
    "from arekit.contrib.bert.run_evaluation import LanguageModelExperimentEvaluator\n",
    "from arekit.contrib.bert.samplers.types import BertSampleFormatterTypes\n",
    "from arekit.contrib.experiments.factory import create_experiment\n",
    "from arekit.contrib.experiments.types import ExperimentTypes\n",
    "from arekit.contrib.source.ruattitudes.io_utils import RuAttitudesVersionsService\n",
    "from arekit.contrib.source.rusentiframes.types import RuSentiFramesVersionsService\n",
    "from arekit.contrib.source.rusentrel.opinions.formatter import RuSentRelOpinionCollectionFormatter\n",
    "\n",
    "# Arguments\n",
    "from args.rusentrel import RuSentRelVersionArg\n",
    "from args.stemmer import StemmerArg\n",
    "from args.terms_per_context import TermsPerContextArg\n",
    "from bert_model_io import BertModelIO\n",
    "from callback import CustomCallback\n",
    "from common import Common\n",
    "\n",
    "# Related project dependencies\n",
    "from data_training import CustomTrainingData\n",
    "from experiment_io import CustomBertIOUtils\n",
    "from run_serialization import create_exp_name_suffix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06600698",
   "metadata": {},
   "source": [
    "2. Provide helper instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897ceede",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomEvalHelper(EvalHelper):\n",
    "\n",
    "    RESULTS_TEMPLATE_FILENAME = u\"test_results_i{it_index}_e{epoch_index}_s{state_name}.tsv\"\n",
    "\n",
    "    def __init__(self, log_dir, state_name, ft_tag):\n",
    "        assert(isinstance(ft_tag, unicode) or ft_tag is None)\n",
    "        self.__log_dir = log_dir\n",
    "        self.__state_name = state_name\n",
    "        self.__ft_tag = ft_tag\n",
    "\n",
    "    def __create_results_filename(self, iter_index, epoch_index):\n",
    "        return CustomEvalHelper.RESULTS_TEMPLATE_FILENAME.format(it_index=iter_index,\n",
    "                                                                 epoch_index=epoch_index,\n",
    "                                                                 state_name=self.__state_name)\n",
    "\n",
    "    def __get_results_dir(self, target_dir):\n",
    "        return Common.combine_tag_with_full_model_name(full_model_name=target_dir,\n",
    "                                                       tag=self.__ft_tag)\n",
    "\n",
    "    def get_results_dir(self, target_dir):\n",
    "        return self.__get_results_dir(target_dir)\n",
    "\n",
    "    def get_results_filename(self, iter_index, epoch_index):\n",
    "        return self.__create_results_filename(iter_index=iter_index, epoch_index=epoch_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268e6d7e",
   "metadata": {},
   "source": [
    "3. Provide predefined parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ef73f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant predefined parameters.\n",
    "max_epochs_count = 200\n",
    "rusentrel_version = RuSentRelVersionArg.default\n",
    "terms_per_context = TermsPerContextArg.default\n",
    "stemmer = StemmerArg.supported[StemmerArg.default]\n",
    "eval_mode = EvaluationModes.Extraction\n",
    "dist_in_terms_between_attitude_ends = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8080f544",
   "metadata": {},
   "source": [
    "4. Setup evaluation grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbfb9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# serializing.py for looking through.\n",
    "grid = {\n",
    "        u\"labels\": [2, 3],\n",
    "        u\"foldings\": [FoldingType.Fixed,\n",
    "                      FoldingType.CrossValidation],\n",
    "        u\"exp_types\": [ExperimentTypes.RuSentRel,\n",
    "                       ExperimentTypes.RuSentRelWithRuAttitudes],\n",
    "        u\"entity_fmts\": [EntityFormattersService.get_type_by_name(ent_fmt)\n",
    "                         for ent_fmt in EntityFormattersService.iter_supported_names()],\n",
    "        u\"sample_types\": [fmt_type for fmt_type in BertSampleFormatterTypes],\n",
    "        u\"ra_names\": [RuAttitudesVersionsService.find_by_name(ra_name)\n",
    "                      for ra_name in RuAttitudesVersionsService.iter_supported_names()],\n",
    "        u'balancing': [True],\n",
    "        u\"frames_versions\": [RuSentiFramesVersionsService.get_type_by_name(fv)\n",
    "                             for fv in RuSentiFramesVersionsService.iter_supported_names()],\n",
    "        u\"state_names\": [# Fine-tuned 2-l states.\n",
    "                         u\"ra-12-bert-base-nli-pretrained-2l\",\n",
    "                         u\"ra-20-bert-base-nli-pretrained-2l\",\n",
    "                         u\"ra-20-bert-large-nli-pretrained-2l\",\n",
    "                         # Fine-tuned 3-l states.\n",
    "                         u\"ra-12-bert-base-nli-pretrained-3l\",\n",
    "                         u\"ra-20-bert-base-neut-nli-pretrained-3l\",\n",
    "                         u\"ra-20-bert-large-neut-nli-pretrained-3l\",\n",
    "                         # Default state.\n",
    "                         u\"multi_cased_L-12_H-768_A-12\",\n",
    "                         u\"rubert_cased_L-12_H-768_A-12\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774aa94f",
   "metadata": {},
   "source": [
    "5. Initialize main evaluation engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a6e1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __run(labels_count, folding_type, exp_type, entity_formatter_type, sample_formatter_type,\n",
    "          balance_samples, ra_version, frames_version, state_name):\n",
    "\n",
    "    full_model_name = Common.create_full_model_name(\n",
    "        sample_fmt_type=sample_formatter_type,\n",
    "        entities_fmt_type=entity_formatter_type,\n",
    "        labels_count=int(labels_count))\n",
    "    extra_name_suffix = create_exp_name_suffix(use_balancing=balance_samples,\n",
    "                                               terms_per_context=terms_per_context,\n",
    "                                               dist_in_terms_between_att_ends=dist_in_terms_between_attitude_ends)\n",
    "\n",
    "    model_io = BertModelIO(full_model_name=full_model_name)\n",
    "\n",
    "    # Setup default evaluator.\n",
    "    evaluator = TwoClassEvaluator(eval_mode)\n",
    "\n",
    "    experiment_data = CustomTrainingData(\n",
    "        labels_scaler=create_labels_scaler(labels_count),\n",
    "        stemmer=stemmer,\n",
    "        evaluator=evaluator,\n",
    "        opinion_formatter=RuSentRelOpinionCollectionFormatter(),\n",
    "        model_io=model_io,\n",
    "        callback=CustomCallback(DataType.Test))\n",
    "\n",
    "    # Composing experiment.\n",
    "    experiment = create_experiment(exp_type=exp_type,\n",
    "                                   experiment_data=experiment_data,\n",
    "                                   folding_type=folding_type,\n",
    "                                   rusentrel_version=rusentrel_version,\n",
    "                                   experiment_io_type=CustomBertIOUtils,\n",
    "                                   ruattitudes_version=ra_version,\n",
    "                                   load_ruattitude_docs=False,\n",
    "                                   do_log=False,\n",
    "                                   extra_name_suffix=extra_name_suffix)\n",
    "\n",
    "    eval_helper = CustomEvalHelper(log_dir=Common.log_dir,\n",
    "                                   state_name=state_name,\n",
    "                                   ft_tag=Common.get_tag_by_ruattitudes_version(ra_version))\n",
    "\n",
    "    engine = LanguageModelExperimentEvaluator(experiment=experiment,\n",
    "                                              data_type=DataType.Test,\n",
    "                                              eval_helper=eval_helper,\n",
    "                                              max_epochs_count=max_epochs_count)\n",
    "\n",
    "    # Starting evaluation process.\n",
    "    engine.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0c3a16",
   "metadata": {},
   "source": [
    "6. Declare runner through all parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    " def run_through_params_grid():\n",
    "        for labels_count in grid[u\"labels\"]:\n",
    "            for folding_type in grid[u\"foldings\"]:\n",
    "                for exp_type in grid[u'exp_types']:\n",
    "                    for entity_formatter_type in grid[u'entity_fmts']:\n",
    "                        for sample_formatter_type in grid[u'sample_types']:\n",
    "                            for balance_samples in grid[u'balancing']:\n",
    "                                for ra_version in grid[u'ra_names']:\n",
    "                                    for frames_version in grid[u'frames_versions']:\n",
    "                                        for state_name in grid[u'state_names']:\n",
    "                                            __run(labels_count=labels_count,\n",
    "                                                  folding_type=folding_type,\n",
    "                                                  exp_type=exp_type,\n",
    "                                                  entity_formatter_type=entity_formatter_type,\n",
    "                                                  sample_formatter_type=sample_formatter_type,\n",
    "                                                  balance_samples=balance_samples,\n",
    "                                                  ra_version=ra_version,\n",
    "                                                  frames_version=frames_version,\n",
    "                                                  state_name=state_name)\n",
    "                                            yield None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1a1b15",
   "metadata": {},
   "source": [
    "7. Finally run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7afeb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Running tqdm, wrapped into progress bar.\n",
    "    grid_sizes = [len(v) for v in grid.values()]\n",
    "    it = progress_bar_defined(iterable=run_through_params_grid(),\n",
    "                              total=np.prod(grid_sizes),\n",
    "                              desc=u\"Analyzing possible experiments\")\n",
    "\n",
    "    for _ in it:\n",
    "        pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
